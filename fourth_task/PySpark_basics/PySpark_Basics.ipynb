{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "trained-moses",
   "metadata": {},
   "source": [
    "import libraries(I provide all libs that I need when make this tasks, if you need some external import them here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "induced-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import max, avg, min, first\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql.functions import monotonically_increasing_id "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-photographer",
   "metadata": {},
   "source": [
    "create local SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "stock-partnership",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "                    .master('local[*]') \\\n",
    "                    .appName('Trainee') \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-blame",
   "metadata": {},
   "source": [
    "read csv with inferschema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "computational-liverpool",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "          .option('header', True) \\\n",
    "          .csv('./ds_salaries.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-dominant",
   "metadata": {},
   "source": [
    "read csv one more time with the same code and you will see that it almostly don't take time, because info already in SparkSession and it will not read nothing\n",
    "from this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aging-neighborhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "            .option('inferschema',True) \\\n",
    "            .csv('./ds_salaries.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mature-tomorrow",
   "metadata": {},
   "source": [
    "write schema of scv on screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "least-communications",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- work_year: string (nullable = true)\n",
      " |-- experience_level: string (nullable = true)\n",
      " |-- employment_type: string (nullable = true)\n",
      " |-- job_title: string (nullable = true)\n",
      " |-- salary: string (nullable = true)\n",
      " |-- salary_currency: string (nullable = true)\n",
      " |-- salary_in_usd: string (nullable = true)\n",
      " |-- employee_residence: string (nullable = true)\n",
      " |-- remote_ratio: string (nullable = true)\n",
      " |-- company_location: string (nullable = true)\n",
      " |-- company_size: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-brother",
   "metadata": {},
   "source": [
    "create schema of this scv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "progressive-dictionary",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField('id', IntegerType(), True),\n",
    "    StructField('work_year', StringType(), True),\n",
    "    StructField('experiecne_level', StringType(), True),\n",
    "    StructField('employment_type', StringType(), True),\n",
    "    StructField('job_title', StringType(), True),\n",
    "    StructField('salary', IntegerType(), True),\n",
    "    StructField('salary_currency', StringType(), True),\n",
    "    StructField('salary_in_usd', IntegerType(), True),\n",
    "    StructField('employee_residence', StringType(), True),\n",
    "    StructField('remote_ratio', IntegerType(), True),\n",
    "    StructField('company_location', StringType(), True),\n",
    "    StructField('company_size', StringType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-sauce",
   "metadata": {},
   "source": [
    "restart kernel without cleaning output and after restarting you need to initialize SparkSession, after initialize start execute only cells from cell with schema=\n",
    "=StructType.... \n",
    "To restart kernel click Kernel, Restart."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-hospital",
   "metadata": {},
   "source": [
    "read ds_salaries with predefined schema and compare results from this cell and cell with inferSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "literary-plaintiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master('local[*]').appName('Trainee').getOrCreate()\n",
    "df = spark.read \\\n",
    "          .option('header', True) \\\n",
    "          .format('csv') \\\n",
    "          .schema(schema) \\\n",
    "          .load('./ds_salaries.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-joint",
   "metadata": {},
   "source": [
    "this happens because read operation is lazy(transformation), but if you use inferschema it start to be action that will create Spark Job, because Spark need to loop throw all file to check datatypes for all columns and this can harm to your code(if we compare to parquet, it will also go to check data types, but parquet provide meta information, so Spark will not go throw all file, he will just read meta information, but csv don't provide such meta information). Also header make Spark to create one more Spark Job to check first line\n",
    "to define name of columns and remember to skeep it when reading. Actual reading start when you will use first action. More about Spark Jobs you will see in next topic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-assurance",
   "metadata": {},
   "source": [
    "write schema of scv on screen one more time and compare with previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "solid-infection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- work_year: string (nullable = true)\n",
      " |-- experiecne_level: string (nullable = true)\n",
      " |-- employment_type: string (nullable = true)\n",
      " |-- job_title: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- salary_currency: string (nullable = true)\n",
      " |-- salary_in_usd: integer (nullable = true)\n",
      " |-- employee_residence: string (nullable = true)\n",
      " |-- remote_ratio: integer (nullable = true)\n",
      " |-- company_location: string (nullable = true)\n",
      " |-- company_size: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-water",
   "metadata": {},
   "source": [
    "now continue to work with one of the dataframes that you create"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-belgium",
   "metadata": {},
   "source": [
    "print data in dataframe using df.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "legendary-alarm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+----------------+---------------+--------------------+--------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "| id|work_year|experiecne_level|employment_type|           job_title|  salary|salary_currency|salary_in_usd|employee_residence|remote_ratio|company_location|company_size|\n",
      "+---+---------+----------------+---------------+--------------------+--------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "|  0|     2020|              MI|             FT|      Data Scientist|   70000|            EUR|        79833|                DE|           0|              DE|           L|\n",
      "|  1|     2020|              SE|             FT|Machine Learning ...|  260000|            USD|       260000|                JP|           0|              JP|           S|\n",
      "|  2|     2020|              SE|             FT|   Big Data Engineer|   85000|            GBP|       109024|                GB|          50|              GB|           M|\n",
      "|  3|     2020|              MI|             FT|Product Data Analyst|   20000|            USD|        20000|                HN|           0|              HN|           S|\n",
      "|  4|     2020|              SE|             FT|Machine Learning ...|  150000|            USD|       150000|                US|          50|              US|           L|\n",
      "|  5|     2020|              EN|             FT|        Data Analyst|   72000|            USD|        72000|                US|         100|              US|           L|\n",
      "|  6|     2020|              SE|             FT| Lead Data Scientist|  190000|            USD|       190000|                US|         100|              US|           S|\n",
      "|  7|     2020|              MI|             FT|      Data Scientist|11000000|            HUF|        35735|                HU|          50|              HU|           L|\n",
      "|  8|     2020|              MI|             FT|Business Data Ana...|  135000|            USD|       135000|                US|         100|              US|           L|\n",
      "|  9|     2020|              SE|             FT|  Lead Data Engineer|  125000|            USD|       125000|                NZ|          50|              NZ|           S|\n",
      "| 10|     2020|              EN|             FT|      Data Scientist|   45000|            EUR|        51321|                FR|           0|              FR|           S|\n",
      "| 11|     2020|              MI|             FT|      Data Scientist| 3000000|            INR|        40481|                IN|           0|              IN|           L|\n",
      "| 12|     2020|              EN|             FT|      Data Scientist|   35000|            EUR|        39916|                FR|           0|              FR|           M|\n",
      "| 13|     2020|              MI|             FT|   Lead Data Analyst|   87000|            USD|        87000|                US|         100|              US|           L|\n",
      "| 14|     2020|              MI|             FT|        Data Analyst|   85000|            USD|        85000|                US|         100|              US|           L|\n",
      "| 15|     2020|              MI|             FT|        Data Analyst|    8000|            USD|         8000|                PK|          50|              PK|           L|\n",
      "| 16|     2020|              EN|             FT|       Data Engineer| 4450000|            JPY|        41689|                JP|         100|              JP|           S|\n",
      "| 17|     2020|              SE|             FT|   Big Data Engineer|  100000|            EUR|       114047|                PL|         100|              GB|           S|\n",
      "| 18|     2020|              EN|             FT|Data Science Cons...|  423000|            INR|         5707|                IN|          50|              IN|           M|\n",
      "| 19|     2020|              MI|             FT|  Lead Data Engineer|   56000|            USD|        56000|                PT|         100|              US|           M|\n",
      "+---+---------+----------------+---------------+--------------------+--------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-medium",
   "metadata": {},
   "source": [
    "print data in dataframe using display(df.toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "connected-dryer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>work_year</th>\n",
       "      <th>experiecne_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_currency</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>70000</td>\n",
       "      <td>EUR</td>\n",
       "      <td>79833</td>\n",
       "      <td>DE</td>\n",
       "      <td>0</td>\n",
       "      <td>DE</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Machine Learning Scientist</td>\n",
       "      <td>260000</td>\n",
       "      <td>USD</td>\n",
       "      <td>260000</td>\n",
       "      <td>JP</td>\n",
       "      <td>0</td>\n",
       "      <td>JP</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Big Data Engineer</td>\n",
       "      <td>85000</td>\n",
       "      <td>GBP</td>\n",
       "      <td>109024</td>\n",
       "      <td>GB</td>\n",
       "      <td>50</td>\n",
       "      <td>GB</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>Product Data Analyst</td>\n",
       "      <td>20000</td>\n",
       "      <td>USD</td>\n",
       "      <td>20000</td>\n",
       "      <td>HN</td>\n",
       "      <td>0</td>\n",
       "      <td>HN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>150000</td>\n",
       "      <td>USD</td>\n",
       "      <td>150000</td>\n",
       "      <td>US</td>\n",
       "      <td>50</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>602</td>\n",
       "      <td>2022</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>154000</td>\n",
       "      <td>USD</td>\n",
       "      <td>154000</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>603</td>\n",
       "      <td>2022</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>126000</td>\n",
       "      <td>USD</td>\n",
       "      <td>126000</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>604</td>\n",
       "      <td>2022</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>129000</td>\n",
       "      <td>USD</td>\n",
       "      <td>129000</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>605</td>\n",
       "      <td>2022</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>150000</td>\n",
       "      <td>USD</td>\n",
       "      <td>150000</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>606</td>\n",
       "      <td>2022</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>AI Scientist</td>\n",
       "      <td>200000</td>\n",
       "      <td>USD</td>\n",
       "      <td>200000</td>\n",
       "      <td>IN</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>607 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id work_year experiecne_level employment_type  \\\n",
       "0      0      2020               MI              FT   \n",
       "1      1      2020               SE              FT   \n",
       "2      2      2020               SE              FT   \n",
       "3      3      2020               MI              FT   \n",
       "4      4      2020               SE              FT   \n",
       "..   ...       ...              ...             ...   \n",
       "602  602      2022               SE              FT   \n",
       "603  603      2022               SE              FT   \n",
       "604  604      2022               SE              FT   \n",
       "605  605      2022               SE              FT   \n",
       "606  606      2022               MI              FT   \n",
       "\n",
       "                      job_title  salary salary_currency  salary_in_usd  \\\n",
       "0                Data Scientist   70000             EUR          79833   \n",
       "1    Machine Learning Scientist  260000             USD         260000   \n",
       "2             Big Data Engineer   85000             GBP         109024   \n",
       "3          Product Data Analyst   20000             USD          20000   \n",
       "4     Machine Learning Engineer  150000             USD         150000   \n",
       "..                          ...     ...             ...            ...   \n",
       "602               Data Engineer  154000             USD         154000   \n",
       "603               Data Engineer  126000             USD         126000   \n",
       "604                Data Analyst  129000             USD         129000   \n",
       "605                Data Analyst  150000             USD         150000   \n",
       "606                AI Scientist  200000             USD         200000   \n",
       "\n",
       "    employee_residence  remote_ratio company_location company_size  \n",
       "0                   DE             0               DE            L  \n",
       "1                   JP             0               JP            S  \n",
       "2                   GB            50               GB            M  \n",
       "3                   HN             0               HN            S  \n",
       "4                   US            50               US            L  \n",
       "..                 ...           ...              ...          ...  \n",
       "602                 US           100               US            M  \n",
       "603                 US           100               US            M  \n",
       "604                 US             0               US            M  \n",
       "605                 US           100               US            M  \n",
       "606                 IN           100               US            L  \n",
       "\n",
       "[607 rows x 12 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-gazette",
   "metadata": {},
   "source": [
    "create df_job_title that consists from all job_titles without duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "friendly-cartridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job_title = df.dropDuplicates(['job_title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offshore-architecture",
   "metadata": {},
   "source": [
    "print all rows from df_job_titles without truncating jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "asian-edition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+----------------+---------------+----------------------------------+-------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "|id |work_year|experiecne_level|employment_type|job_title                         |salary |salary_currency|salary_in_usd|employee_residence|remote_ratio|company_location|company_size|\n",
      "+---+---------+----------------+---------------+----------------------------------+-------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "|77 |2021     |MI              |PT             |3D Computer Vision Researcher     |400000 |INR            |5409         |IN                |50          |IN              |M           |\n",
      "|52 |2020     |EN              |FT             |AI Scientist                      |300000 |DKK            |45896        |DK                |50          |DK              |S           |\n",
      "|344|2022     |EX              |FT             |Analytics Engineer                |175000 |USD            |175000       |US                |100         |US              |M           |\n",
      "|82 |2021     |MI              |FT             |Applied Data Scientist            |68000  |CAD            |54238        |GB                |50          |CA              |L           |\n",
      "|132|2021     |MI              |FT             |Applied Machine Learning Scientist|38400  |USD            |38400        |VN                |100         |US              |M           |\n",
      "|23 |2020     |MI              |FT             |BI Data Analyst                   |98000  |USD            |98000        |US                |0           |US              |M           |\n",
      "|255|2021     |SE              |FT             |Big Data Architect                |125000 |CAD            |99703        |CA                |50          |CA              |M           |\n",
      "|2  |2020     |SE              |FT             |Big Data Engineer                 |85000  |GBP            |109024       |GB                |50          |GB              |M           |\n",
      "|8  |2020     |MI              |FT             |Business Data Analyst             |135000 |USD            |135000       |US                |100         |US              |L           |\n",
      "|95 |2021     |MI              |FT             |Cloud Data Engineer               |120000 |SGD            |89294        |SG                |50          |SG              |L           |\n",
      "|54 |2020     |SE              |FL             |Computer Vision Engineer          |60000  |USD            |60000        |RU                |100         |US              |S           |\n",
      "|98 |2021     |EN              |FT             |Computer Vision Software Engineer |70000  |USD            |70000        |US                |100         |US              |M           |\n",
      "|5  |2020     |EN              |FT             |Data Analyst                      |72000  |USD            |72000        |US                |100         |US              |L           |\n",
      "|80 |2021     |SE              |FT             |Data Analytics Engineer           |67000  |EUR            |79197        |DE                |100         |DE              |L           |\n",
      "|523|2022     |SE              |FT             |Data Analytics Lead               |405000 |USD            |405000       |US                |100         |US              |L           |\n",
      "|158|2021     |SE              |FT             |Data Analytics Manager            |120000 |USD            |120000       |US                |100         |US              |M           |\n",
      "|169|2021     |MI              |FT             |Data Architect                    |150000 |USD            |150000       |US                |100         |US              |L           |\n",
      "|16 |2020     |EN              |FT             |Data Engineer                     |4450000|JPY            |41689        |JP                |100         |JP              |S           |\n",
      "|30 |2020     |MI              |FT             |Data Engineering Manager          |51999  |EUR            |59303        |DE                |100         |DE              |S           |\n",
      "|18 |2020     |EN              |FT             |Data Science Consultant           |423000 |INR            |5707         |IN                |50          |IN              |M           |\n",
      "+---+---------+----------------+---------------+----------------------------------+-------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_job_title.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-pharmacy",
   "metadata": {},
   "source": [
    "create  df_analytic that will consists from max, avg, min USD salaries for all job_titles using groupBy. name of fields is avg_salary, min_salary, max_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "naval-roller",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analytic = df_job_title.groupBy('job_title') \\\n",
    "                          .agg(max('salary_in_usd').alias('max_salary'),\n",
    "                               min('salary_in_usd').alias('min_salary'),\n",
    "                               avg('salary_in_usd').alias('avg_salary'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-pledge",
   "metadata": {},
   "source": [
    "print all rows from df_analytic without trancating jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bacterial-depression",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+----------+----------+----------+\n",
      "|job_title                               |max_salary|min_salary|avg_salary|\n",
      "+----------------------------------------+----------+----------+----------+\n",
      "|3D Computer Vision Researcher           |5409      |5409      |5409.0    |\n",
      "|Lead Data Engineer                      |125000    |125000    |125000.0  |\n",
      "|Head of Machine Learning                |79039     |79039     |79039.0   |\n",
      "|Data Specialist                         |165000    |165000    |165000.0  |\n",
      "|Data Analytics Lead                     |405000    |405000    |405000.0  |\n",
      "|Machine Learning Scientist              |260000    |260000    |260000.0  |\n",
      "|Lead Data Analyst                       |87000     |87000     |87000.0   |\n",
      "|Data Engineering Manager                |59303     |59303     |59303.0   |\n",
      "|Staff Data Scientist                    |105000    |105000    |105000.0  |\n",
      "|ETL Developer                           |54957     |54957     |54957.0   |\n",
      "|Director of Data Engineering            |113476    |113476    |113476.0  |\n",
      "|Product Data Analyst                    |20000     |20000     |20000.0   |\n",
      "|Principal Data Scientist                |148261    |148261    |148261.0  |\n",
      "|AI Scientist                            |45896     |45896     |45896.0   |\n",
      "|Director of Data Science                |325000    |325000    |325000.0  |\n",
      "|Machine Learning Engineer               |150000    |150000    |150000.0  |\n",
      "|Lead Data Scientist                     |190000    |190000    |190000.0  |\n",
      "|Machine Learning Infrastructure Engineer|50180     |50180     |50180.0   |\n",
      "|Data Science Engineer                   |40189     |40189     |40189.0   |\n",
      "|Machine Learning Manager                |117104    |117104    |117104.0  |\n",
      "+----------------------------------------+----------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_analytic.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-color",
   "metadata": {},
   "source": [
    "now you need to add in df_analytic column row_id, that will show order of all job_titles depending on avg salary. they should be descending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "nearby-treasurer",
   "metadata": {},
   "outputs": [],
   "source": [
    "windowSpec = Window.orderBy(col('avg_salary').desc())\n",
    "df_analytic = df_analytic.withColumn('id', row_number().over(windowSpec))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documented-catalog",
   "metadata": {},
   "source": [
    "print all data from df_analytic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "confirmed-monitoring",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>max_salary</th>\n",
       "      <th>min_salary</th>\n",
       "      <th>avg_salary</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Financial Data Analyst</td>\n",
       "      <td>450000</td>\n",
       "      <td>450000</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analytics Lead</td>\n",
       "      <td>405000</td>\n",
       "      <td>405000</td>\n",
       "      <td>405000.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Director of Data Science</td>\n",
       "      <td>325000</td>\n",
       "      <td>325000</td>\n",
       "      <td>325000.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Machine Learning Scientist</td>\n",
       "      <td>260000</td>\n",
       "      <td>260000</td>\n",
       "      <td>260000.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Head of Data</td>\n",
       "      <td>235000</td>\n",
       "      <td>235000</td>\n",
       "      <td>235000.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Principal Data Engineer</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Science Manager</td>\n",
       "      <td>190200</td>\n",
       "      <td>190200</td>\n",
       "      <td>190200.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>190000</td>\n",
       "      <td>190000</td>\n",
       "      <td>190000.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Analytics Engineer</td>\n",
       "      <td>175000</td>\n",
       "      <td>175000</td>\n",
       "      <td>175000.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Principal Data Analyst</td>\n",
       "      <td>170000</td>\n",
       "      <td>170000</td>\n",
       "      <td>170000.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Specialist</td>\n",
       "      <td>165000</td>\n",
       "      <td>165000</td>\n",
       "      <td>165000.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>150000</td>\n",
       "      <td>150000</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Architect</td>\n",
       "      <td>150000</td>\n",
       "      <td>150000</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>148261</td>\n",
       "      <td>148261</td>\n",
       "      <td>148261.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>135000</td>\n",
       "      <td>135000</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Lead Data Engineer</td>\n",
       "      <td>125000</td>\n",
       "      <td>125000</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data Analytics Manager</td>\n",
       "      <td>120000</td>\n",
       "      <td>120000</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Machine Learning Manager</td>\n",
       "      <td>117104</td>\n",
       "      <td>117104</td>\n",
       "      <td>117104.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Director of Data Engineering</td>\n",
       "      <td>113476</td>\n",
       "      <td>113476</td>\n",
       "      <td>113476.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Big Data Engineer</td>\n",
       "      <td>109024</td>\n",
       "      <td>109024</td>\n",
       "      <td>109024.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Staff Data Scientist</td>\n",
       "      <td>105000</td>\n",
       "      <td>105000</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Machine Learning Developer</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Big Data Architect</td>\n",
       "      <td>99703</td>\n",
       "      <td>99703</td>\n",
       "      <td>99703.0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>BI Data Analyst</td>\n",
       "      <td>98000</td>\n",
       "      <td>98000</td>\n",
       "      <td>98000.0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Cloud Data Engineer</td>\n",
       "      <td>89294</td>\n",
       "      <td>89294</td>\n",
       "      <td>89294.0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Marketing Data Analyst</td>\n",
       "      <td>88654</td>\n",
       "      <td>88654</td>\n",
       "      <td>88654.0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Lead Machine Learning Engineer</td>\n",
       "      <td>87932</td>\n",
       "      <td>87932</td>\n",
       "      <td>87932.0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Lead Data Analyst</td>\n",
       "      <td>87000</td>\n",
       "      <td>87000</td>\n",
       "      <td>87000.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Head of Data Science</td>\n",
       "      <td>85000</td>\n",
       "      <td>85000</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>79833</td>\n",
       "      <td>79833</td>\n",
       "      <td>79833.0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Data Analytics Engineer</td>\n",
       "      <td>79197</td>\n",
       "      <td>79197</td>\n",
       "      <td>79197.0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Head of Machine Learning</td>\n",
       "      <td>79039</td>\n",
       "      <td>79039</td>\n",
       "      <td>79039.0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>72000</td>\n",
       "      <td>72000</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Computer Vision Software Engineer</td>\n",
       "      <td>70000</td>\n",
       "      <td>70000</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Finance Data Analyst</td>\n",
       "      <td>61896</td>\n",
       "      <td>61896</td>\n",
       "      <td>61896.0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Computer Vision Engineer</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Data Engineering Manager</td>\n",
       "      <td>59303</td>\n",
       "      <td>59303</td>\n",
       "      <td>59303.0</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ETL Developer</td>\n",
       "      <td>54957</td>\n",
       "      <td>54957</td>\n",
       "      <td>54957.0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Applied Data Scientist</td>\n",
       "      <td>54238</td>\n",
       "      <td>54238</td>\n",
       "      <td>54238.0</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Machine Learning Infrastructure Engineer</td>\n",
       "      <td>50180</td>\n",
       "      <td>50180</td>\n",
       "      <td>50180.0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>AI Scientist</td>\n",
       "      <td>45896</td>\n",
       "      <td>45896</td>\n",
       "      <td>45896.0</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Research Scientist</td>\n",
       "      <td>42000</td>\n",
       "      <td>42000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>41689</td>\n",
       "      <td>41689</td>\n",
       "      <td>41689.0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Data Science Engineer</td>\n",
       "      <td>40189</td>\n",
       "      <td>40189</td>\n",
       "      <td>40189.0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Applied Machine Learning Scientist</td>\n",
       "      <td>38400</td>\n",
       "      <td>38400</td>\n",
       "      <td>38400.0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NLP Engineer</td>\n",
       "      <td>37236</td>\n",
       "      <td>37236</td>\n",
       "      <td>37236.0</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Product Data Analyst</td>\n",
       "      <td>20000</td>\n",
       "      <td>20000</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>ML Engineer</td>\n",
       "      <td>15966</td>\n",
       "      <td>15966</td>\n",
       "      <td>15966.0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Data Science Consultant</td>\n",
       "      <td>5707</td>\n",
       "      <td>5707</td>\n",
       "      <td>5707.0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3D Computer Vision Researcher</td>\n",
       "      <td>5409</td>\n",
       "      <td>5409</td>\n",
       "      <td>5409.0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   job_title  max_salary  min_salary  \\\n",
       "0                     Financial Data Analyst      450000      450000   \n",
       "1                        Data Analytics Lead      405000      405000   \n",
       "2                   Director of Data Science      325000      325000   \n",
       "3                 Machine Learning Scientist      260000      260000   \n",
       "4                               Head of Data      235000      235000   \n",
       "5                    Principal Data Engineer      200000      200000   \n",
       "6                       Data Science Manager      190200      190200   \n",
       "7                        Lead Data Scientist      190000      190000   \n",
       "8                         Analytics Engineer      175000      175000   \n",
       "9                     Principal Data Analyst      170000      170000   \n",
       "10                           Data Specialist      165000      165000   \n",
       "11                 Machine Learning Engineer      150000      150000   \n",
       "12                            Data Architect      150000      150000   \n",
       "13                  Principal Data Scientist      148261      148261   \n",
       "14                     Business Data Analyst      135000      135000   \n",
       "15                        Lead Data Engineer      125000      125000   \n",
       "16                    Data Analytics Manager      120000      120000   \n",
       "17                  Machine Learning Manager      117104      117104   \n",
       "18              Director of Data Engineering      113476      113476   \n",
       "19                         Big Data Engineer      109024      109024   \n",
       "20                      Staff Data Scientist      105000      105000   \n",
       "21                Machine Learning Developer      100000      100000   \n",
       "22                        Big Data Architect       99703       99703   \n",
       "23                           BI Data Analyst       98000       98000   \n",
       "24                       Cloud Data Engineer       89294       89294   \n",
       "25                    Marketing Data Analyst       88654       88654   \n",
       "26            Lead Machine Learning Engineer       87932       87932   \n",
       "27                         Lead Data Analyst       87000       87000   \n",
       "28                      Head of Data Science       85000       85000   \n",
       "29                            Data Scientist       79833       79833   \n",
       "30                   Data Analytics Engineer       79197       79197   \n",
       "31                  Head of Machine Learning       79039       79039   \n",
       "32                              Data Analyst       72000       72000   \n",
       "33         Computer Vision Software Engineer       70000       70000   \n",
       "34                      Finance Data Analyst       61896       61896   \n",
       "35                  Computer Vision Engineer       60000       60000   \n",
       "36                  Data Engineering Manager       59303       59303   \n",
       "37                             ETL Developer       54957       54957   \n",
       "38                    Applied Data Scientist       54238       54238   \n",
       "39  Machine Learning Infrastructure Engineer       50180       50180   \n",
       "40                              AI Scientist       45896       45896   \n",
       "41                        Research Scientist       42000       42000   \n",
       "42                             Data Engineer       41689       41689   \n",
       "43                     Data Science Engineer       40189       40189   \n",
       "44        Applied Machine Learning Scientist       38400       38400   \n",
       "45                              NLP Engineer       37236       37236   \n",
       "46                      Product Data Analyst       20000       20000   \n",
       "47                               ML Engineer       15966       15966   \n",
       "48                   Data Science Consultant        5707        5707   \n",
       "49             3D Computer Vision Researcher        5409        5409   \n",
       "\n",
       "    avg_salary  id  \n",
       "0     450000.0   1  \n",
       "1     405000.0   2  \n",
       "2     325000.0   3  \n",
       "3     260000.0   4  \n",
       "4     235000.0   5  \n",
       "5     200000.0   6  \n",
       "6     190200.0   7  \n",
       "7     190000.0   8  \n",
       "8     175000.0   9  \n",
       "9     170000.0  10  \n",
       "10    165000.0  11  \n",
       "11    150000.0  12  \n",
       "12    150000.0  13  \n",
       "13    148261.0  14  \n",
       "14    135000.0  15  \n",
       "15    125000.0  16  \n",
       "16    120000.0  17  \n",
       "17    117104.0  18  \n",
       "18    113476.0  19  \n",
       "19    109024.0  20  \n",
       "20    105000.0  21  \n",
       "21    100000.0  22  \n",
       "22     99703.0  23  \n",
       "23     98000.0  24  \n",
       "24     89294.0  25  \n",
       "25     88654.0  26  \n",
       "26     87932.0  27  \n",
       "27     87000.0  28  \n",
       "28     85000.0  29  \n",
       "29     79833.0  30  \n",
       "30     79197.0  31  \n",
       "31     79039.0  32  \n",
       "32     72000.0  33  \n",
       "33     70000.0  34  \n",
       "34     61896.0  35  \n",
       "35     60000.0  36  \n",
       "36     59303.0  37  \n",
       "37     54957.0  38  \n",
       "38     54238.0  39  \n",
       "39     50180.0  40  \n",
       "40     45896.0  41  \n",
       "41     42000.0  42  \n",
       "42     41689.0  43  \n",
       "43     40189.0  44  \n",
       "44     38400.0  45  \n",
       "45     37236.0  46  \n",
       "46     20000.0  47  \n",
       "47     15966.0  48  \n",
       "48      5707.0  49  \n",
       "49      5409.0  50  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analytic.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-quarter",
   "metadata": {},
   "source": [
    "it isn't beautifull, so we need to put now row_id on first place in df_analytic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ranging-tribune",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analytic = df_analytic.select(['id', 'job_title', 'avg_salary', 'min_salary', 'max_salary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reliable-amsterdam",
   "metadata": {},
   "source": [
    "print df_analytic now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "classical-biology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+----------+----------+----------+\n",
      "| id|           job_title|avg_salary|min_salary|max_salary|\n",
      "+---+--------------------+----------+----------+----------+\n",
      "|  1|Financial Data An...|  450000.0|    450000|    450000|\n",
      "|  2| Data Analytics Lead|  405000.0|    405000|    405000|\n",
      "|  3|Director of Data ...|  325000.0|    325000|    325000|\n",
      "|  4|Machine Learning ...|  260000.0|    260000|    260000|\n",
      "|  5|        Head of Data|  235000.0|    235000|    235000|\n",
      "|  6|Principal Data En...|  200000.0|    200000|    200000|\n",
      "|  7|Data Science Manager|  190200.0|    190200|    190200|\n",
      "|  8| Lead Data Scientist|  190000.0|    190000|    190000|\n",
      "|  9|  Analytics Engineer|  175000.0|    175000|    175000|\n",
      "| 10|Principal Data An...|  170000.0|    170000|    170000|\n",
      "| 11|     Data Specialist|  165000.0|    165000|    165000|\n",
      "| 12|Machine Learning ...|  150000.0|    150000|    150000|\n",
      "| 13|      Data Architect|  150000.0|    150000|    150000|\n",
      "| 14|Principal Data Sc...|  148261.0|    148261|    148261|\n",
      "| 15|Business Data Ana...|  135000.0|    135000|    135000|\n",
      "| 16|  Lead Data Engineer|  125000.0|    125000|    125000|\n",
      "| 17|Data Analytics Ma...|  120000.0|    120000|    120000|\n",
      "| 18|Machine Learning ...|  117104.0|    117104|    117104|\n",
      "| 19|Director of Data ...|  113476.0|    113476|    113476|\n",
      "| 20|   Big Data Engineer|  109024.0|    109024|    109024|\n",
      "+---+--------------------+----------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_analytic.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-queensland",
   "metadata": {},
   "source": [
    "here you need to create df_exp_lvl with the biggest usd_salary(biggest_salary) for each experience_level(you need to save all fields like in entire dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dental-wrist",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp_lvl = df.groupBy('experiecne_level') \\\n",
    "                .agg(first('work_year').alias('work_year'),\n",
    "                     first('experiecne_level').alias('experiecne_level'),\n",
    "                     first('employment_type').alias('employment_type'),\n",
    "                     first('job_title').alias('job_title'),\n",
    "                     first('salary').alias('salary'),\n",
    "                     first('salary_currency').alias('salary_currency'),\n",
    "                     first('employee_residence').alias('employee_residence'),\n",
    "                     first('remote_ratio').alias('remote_ratio'),\n",
    "                     first('company_location').alias('company_location'),\n",
    "                     first('company_size').alias('company_size'),\n",
    "                     max('salary_in_usd').alias('max_salary'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-hierarchy",
   "metadata": {},
   "source": [
    "print here df_exp_lvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "standing-toilet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+----------------+---------------+--------------------+------+---------------+------------------+------------+----------------+------------+----------+\n",
      "|experiecne_level|work_year|experiecne_level|employment_type|           job_title|salary|salary_currency|employee_residence|remote_ratio|company_location|company_size|max_salary|\n",
      "+----------------+---------+----------------+---------------+--------------------+------+---------------+------------------+------------+----------------+------------+----------+\n",
      "|              EN|     2020|              EN|             FT|        Data Analyst| 72000|            USD|                US|         100|              US|           L|    250000|\n",
      "|              EX|     2020|              EX|             FT|Director of Data ...|325000|            USD|                US|         100|              US|           L|    600000|\n",
      "|              MI|     2020|              MI|             FT|      Data Scientist| 70000|            EUR|                DE|           0|              DE|           L|    450000|\n",
      "|              SE|     2020|              SE|             FT|Machine Learning ...|260000|            USD|                JP|           0|              JP|           S|    412000|\n",
      "+----------------+---------+----------------+---------------+--------------------+------+---------------+------------------+------------+----------------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_exp_lvl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-mortgage",
   "metadata": {},
   "source": [
    "create df_best that consists from rows where salary of guy same as biggest salary for other people in his exp_lvl and choose only columns: id, experience_level, biggest_salary, employee_residence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "toxic-prompt",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `max_salary` cannot be resolved. Did you mean one of the following? [`salary`, `work_year`, `id`, `job_title`, `company_size`].;\n'Filter (salary_in_usd#7 = 'max_salary)\n+- Relation [id#0,work_year#1,experiecne_level#2,employment_type#3,job_title#4,salary#5,salary_currency#6,salary_in_usd#7,employee_residence#8,remote_ratio#9,company_location#10,company_size#11] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m df_join \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mjoin(df_exp_lvl, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexperiecne_level\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m df_best \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msalary_in_usd\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_salary\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py:3325\u001b[0m, in \u001b[0;36mDataFrame.filter\u001b[0;34m(self, condition)\u001b[0m\n\u001b[1;32m   3323\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mfilter(condition)\n\u001b[1;32m   3324\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(condition, Column):\n\u001b[0;32m-> 3325\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcondition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3326\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3327\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m   3328\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_COLUMN_OR_STR\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3329\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcondition\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(condition)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[1;32m   3330\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `max_salary` cannot be resolved. Did you mean one of the following? [`salary`, `work_year`, `id`, `job_title`, `company_size`].;\n'Filter (salary_in_usd#7 = 'max_salary)\n+- Relation [id#0,work_year#1,experiecne_level#2,employment_type#3,job_title#4,salary#5,salary_currency#6,salary_in_usd#7,employee_residence#8,remote_ratio#9,company_location#10,company_size#11] csv\n"
     ]
    }
   ],
   "source": [
    "df_join = df.join(df_exp_lvl, on='experiecne_level', how='inner')\n",
    "df_best = df.filter(col('salary_in_usd')== col('max_salary'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complex-librarian",
   "metadata": {},
   "source": [
    "print df_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-texas",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "integral-brass",
   "metadata": {},
   "source": [
    "drop duplicates if exist by experience_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-marine",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "connected-credit",
   "metadata": {},
   "source": [
    "print df_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specified-wellington",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "facial-plant",
   "metadata": {},
   "source": [
    "create df_new_best from df_best without id, and make the next: when exp_level = MI we want middle, when SE we want senior, else Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-retail",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "changing-fairy",
   "metadata": {},
   "source": [
    "print df_new_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-framework",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "mineral-status",
   "metadata": {},
   "source": [
    "write df_new_best like 1.csv and load then it to df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-progress",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "vocal-shooting",
   "metadata": {},
   "source": [
    "print df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-viewer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-progress",
   "metadata": {},
   "source": [
    "filter df_final to delete experience_level where it Null, then join this table by biggest_salary(salary_in_usd) and employee_residence with entire df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-polymer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "variable-twins",
   "metadata": {},
   "source": [
    "print df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-block",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "variable-moore",
   "metadata": {},
   "source": [
    "last task is to save in variable and then print this variable of the biggest salary_in_usd from df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-institution",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "stopped-procedure",
   "metadata": {},
   "source": [
    "It is the end of PySpark basics. In other lessons you will learn optimizations technics and how to make distributed system"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
